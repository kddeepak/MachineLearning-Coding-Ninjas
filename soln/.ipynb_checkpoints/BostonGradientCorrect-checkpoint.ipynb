{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (127,13) (14,) (127,13) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4b801a694587>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predictions1.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-4b801a694587>\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mdata1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_boston_x.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mX_test_scaled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predictions1.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y, copy)\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (127,13) (14,) (127,13) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def step_gradient(data,learning_rate,m):\n",
    "    x=data[:,0:13] #13 columns\n",
    "    y=data[:,13]\n",
    "    #Converting x to a dataframe df for adding a new column.\n",
    "    df1=pd.DataFrame(x)\n",
    "    df1['s7']=1 #Added a 14th column with all 1s in place of 'c'.\n",
    "    #print(df1.describe())\n",
    "    #And then reconverting back into a list.\n",
    "    x1=df1.values\n",
    "    m_slope=np.zeros(14)\n",
    "    M=len(data)\n",
    "    for i in range(M):\n",
    "        for j in range(14):\n",
    "            sum=0\n",
    "            for k in range(14):\n",
    "                sum+=m[k]*x1[i,k]\n",
    "            m_slope[j]+=(-2/M)*(y[i]-sum)*x1[i,j]\n",
    "            \n",
    "    for i in range(14):\n",
    "        m[i]=m[i]-learning_rate*m_slope[i]\n",
    "    return m\n",
    "        \n",
    "    \n",
    "    \n",
    "def calculate_cost(data,m):\n",
    "    x=data[:,0:13]\n",
    "    y=data[:,13]\n",
    "    df1=pd.DataFrame(x)\n",
    "    df1['s7']=1\n",
    "    x1=df1.values\n",
    "    total_cost=0\n",
    "    M=len(data)\n",
    "    for i in range(M):\n",
    "        sum=0\n",
    "        for j in range(14):\n",
    "            sum+=m[j]*x1[i,j]\n",
    "        total_cost+=(1/M)*((y[i]-sum)**2)\n",
    "    return total_cost\n",
    "\n",
    "def gd(data,learning_rate,num_iterations):\n",
    "    m=np.zeros(14)\n",
    "    for i in range(num_iterations):\n",
    "        m=step_gradient(data,learning_rate,m)\n",
    "        #cost=calculate_cost(data,m)\n",
    "        #print(cost)\n",
    "    return m\n",
    "\n",
    "def predict(data1,m):\n",
    "    df=pd.DataFrame(data1)\n",
    "    n=len(df.columns)\n",
    "    df[n]=1\n",
    "    x1=df.values\n",
    "    y_pred=np.dot(x1,m)\n",
    "   \n",
    "    return y_pred\n",
    "    \n",
    "    \n",
    "def run():\n",
    "    data=np.genfromtxt(\"training_boston_x_y.csv\", delimiter=\",\")\n",
    "    learning_rate=0.1\n",
    "    num_iterations=20\n",
    "    scaler=preprocessing.StandardScaler().fit(data)\n",
    "    X_train_scaled=scaler.transform(data)\n",
    "    m=gd(data,learning_rate,num_iterations)\n",
    "    data1=np.genfromtxt(\"test_boston_x.csv\", delimiter=\",\")\n",
    "    X_test_scaled=scaler.transform(data1)\n",
    "    y_pred=predict(data1,m)\n",
    "    np.savetxt(\"predictions1.csv\",y_pred,delimiter=\",\")\n",
    "    \n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
