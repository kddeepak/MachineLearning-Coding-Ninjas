{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets \n",
    "boston= datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepgradient(data, y , learning_rate , m , row , feature):\n",
    "    m_slope=np.zeros(feature)\n",
    "    l=len(data)\n",
    "#     for j in range(len(m_slope)):\n",
    "#         m_slope=(-2/l)*(y-m*x)*x[j]\n",
    "    for j in range(len(m_slope)):   ## this loop we ran for m value of every feature\n",
    "        for i in range(l):           ## this use for iterarte every row of a particular feature\n",
    "            mul=0\n",
    "            for k in range(14):\n",
    "                mul+= m[k]*data[i,k]\n",
    "            #m_slope[j]+= (-2/l)*( y[i]- (m[j]*data[i,j]))*data[i,j]\n",
    "            m_slope[j]+= (-2/l)*( y[i]- mul)*data[i,j]\n",
    "    for i in range(14):\n",
    "        m[i]=m[i]-learning_rate*m_slope[i]\n",
    "    return m\n",
    "\n",
    "\n",
    "\n",
    "def gd(data, y , learning_rate , no_itr , row , feature):\n",
    "    m=np.zeros(14)  ## sare m ka array create kr k 0 fill kr liya\n",
    "    for i in range(no_itr):\n",
    "        m=stepgradient(data, y, learning_rate, m,row , feature)\n",
    "        print(cost(data,y,m))\n",
    "    return(m)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(data,y,m):\n",
    "    cost=0\n",
    "    l=len(data)\n",
    "    for i in range(l):\n",
    "        mul=0\n",
    "        for k in range(14):\n",
    "            mul+= m[k]*data[i,k]\n",
    "        cost += (1/l)*((y[i] * mul)**2)\n",
    "    return (cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    test_data=np.loadtxt(\"0000000000002417_test_boston_x_test.csv\" , delimiter=\",\")\n",
    "    old_data=np.loadtxt(\"0000000000002417_training_boston_x_y_train.csv\" , delimiter=\",\")\n",
    "   # olddata = np.loadtxt(\"data.csv\", delimiter=\",\")\n",
    "    y=old_data[:,13]   # yha output wala column nikal liya\n",
    "    row=len(y)\n",
    "       # intercept wale column ke liye one add kr liya\n",
    "    x=old_data[:,0:13]\n",
    "    df=pd.DataFrame(x)\n",
    "    df[\"13\"]=1\n",
    "    data=df.values\n",
    "    # data=np.append(olddata[:,0] , z , axis=1)\n",
    "    \n",
    "    feature=14    #### this variable decides ki m wala array kitna bda ho kitne m aayenge\n",
    "    learning_rate=0.000001\n",
    "    no_itr=100\n",
    "    m=gd(data , y , learning_rate , no_itr , row , feature)\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4726572128714744e-06\n",
      "2.1890472453657596e-05\n",
      "4.925321112968535e-05\n",
      "8.756063865370743e-05\n",
      "0.00013681252044390246\n",
      "0.00019700862192387398\n",
      "0.00026814870852265223\n",
      "0.0003502325456746911\n",
      "0.0004432598988198704\n",
      "0.000547230533403496\n",
      "0.0006621442148762967\n",
      "0.0007880007086944262\n",
      "0.0009247997803194677\n",
      "0.0010725411952184195\n",
      "0.0012312247188637126\n",
      "0.0014008501167331988\n",
      "0.0015814171543101555\n",
      "0.0017729255970832826\n",
      "0.0019753752105467013\n",
      "0.0021887657601999642\n",
      "0.0024130970115480393\n",
      "0.0026483687301013274\n",
      "0.0028945806813756407\n",
      "0.003151732630892224\n",
      "0.0034198243441777407\n",
      "0.0036988555867642765\n",
      "0.0039888261241893515\n",
      "0.0042897357219958835\n",
      "0.004601584145732242\n",
      "0.004924371160952201\n",
      "0.005258096533214953\n",
      "0.005602760028085131\n",
      "0.005958361411132777\n",
      "0.006324900447933362\n",
      "0.006702376904067763\n",
      "0.00709079054512229\n",
      "0.0074901411366886965\n",
      "0.00790042844436411\n",
      "0.008321652233751113\n",
      "0.008753812270457717\n",
      "0.009196908320097305\n",
      "0.009650940148288741\n",
      "0.010115907520656282\n",
      "0.010591810202829594\n",
      "0.011078647960443787\n",
      "0.01157642055913938\n",
      "0.0120851277645623\n",
      "0.012604769342363913\n",
      "0.013135345058201008\n",
      "0.013676854677735786\n",
      "0.014229297966635855\n",
      "0.014792674690574248\n",
      "0.015366984615229434\n",
      "0.0159522275062853\n",
      "0.016548403129431153\n",
      "0.017155511250361643\n",
      "0.017773551634776993\n",
      "0.018402524048382683\n",
      "0.01904242825688975\n",
      "0.019693264026014536\n",
      "0.020355031121478868\n",
      "0.021027729309009976\n",
      "0.02171135835434046\n",
      "0.022405918023208498\n",
      "0.023111408081357473\n",
      "0.023827828294536304\n",
      "0.024555178428499295\n",
      "0.025293458249006254\n",
      "0.026042667521822247\n",
      "0.02680280601271789\n",
      "0.027573873487469168\n",
      "0.028355869711857464\n",
      "0.0291487944516696\n",
      "0.029952647472697828\n",
      "0.030767428540739803\n",
      "0.03159313742159862\n",
      "0.03242977388108268\n",
      "0.03327733768500598\n",
      "0.03413582859918774\n",
      "0.03500524638945276\n",
      "0.03588559082163123\n",
      "0.03677686166155866\n",
      "0.03767905867507608\n",
      "0.03859218162802981\n",
      "0.03951623028627172\n",
      "0.04045120441565898\n",
      "0.04139710378205428\n",
      "0.042353928151325666\n",
      "0.04332167728934663\n",
      "0.04430035096199608\n",
      "0.04528994893515835\n",
      "0.04629047097472291\n",
      "0.04730191684658521\n",
      "0.0483242863166456\n",
      "0.0493575791508101\n",
      "0.0504017951149901\n",
      "0.05145693397510232\n",
      "0.0525229954970691\n",
      "0.05359997944681784\n",
      "0.054687885590281725\n",
      "[-0.00064866  0.00060156 -0.00075841  0.00047427 -0.00065077  0.00140758\n",
      " -0.00048527  0.00044342 -0.00047633 -0.00065649 -0.0008396   0.0005558\n",
      " -0.0013318   0.00452146]\n"
     ]
    }
   ],
   "source": [
    "run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
