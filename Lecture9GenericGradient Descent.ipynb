{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Gradient Descent Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(m,points):\n",
    "    ans =[]\n",
    "    for j in range(len(points)):\n",
    "        y=0\n",
    "        for i in range(len(points[0])):\n",
    "            y+=m[i]*points[j,i]\n",
    "        y+=m[-1]\n",
    "        ans.append(y)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(points,m):\n",
    "    totcost=0\n",
    "    for j in range(len(points)):\n",
    "        sm =0\n",
    "        for i in range(len(points[0])-1):\n",
    "            sm+=m[i]*points[j,i]\n",
    "        sm+=m[len(points[0])-1]\n",
    "        \n",
    "        totcost +=(1/len(points))*(((points[j,len(points[0])-1])-(sm))**2)\n",
    "    return totcost\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(points,alpha,m):\n",
    "    \n",
    "    for j in range(len(points[0])):\n",
    "        m_slope=0\n",
    "        for i in range(len(points)):\n",
    "            sm=0\n",
    "            for k in range(len(points[0])-1):\n",
    "                sm+=m[k]*points[i,k]\n",
    "            sm+=m[len(points[0])-1]\n",
    "            if j!=len(points[0])-1:\n",
    "                m_slope+=(-2/len(points))*(points[i,10]-sm)*points[i,j]\n",
    "            else:\n",
    "                m_slope+=(-2/len(points))*(points[i,10]-sm)*1\n",
    "            \n",
    "        m[j]=m[j]-alpha*m_slope\n",
    "    \n",
    "    return m\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(points,alpha,iterations):\n",
    "    m =[0 for i in range(len(points[0]))]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        m = step_gradient(points,alpha,m)\n",
    "        #print(i,\" cost:\",cost(points,m))\n",
    "    return m    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    data = np.genfromtxt('0000000000002417_training_boston_x_y_train.csv',delimiter=',')\n",
    "    test_data =  np.genfromtxt('0000000000002417_test_boston_x_test.csv',delimiter=',')\n",
    "    learning_rate = 0.1\n",
    "    num_iterations = 200\n",
    "    #print(data)\n",
    "    m= gd(test_data,learning_rate,num_iterations)\n",
    "    #print(len(m))\n",
    "    ans = predict(m,test_data)\n",
    "    ans = np.array(ans)\n",
    "    print(ans)\n",
    "    an = np.around(ans,decimals=5)\n",
    "    print(an)\n",
    "    np.savetxt('prediction_boston_dataset.csv',an, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80577415 -1.1339965   1.17519859 -0.76396692  1.12814272  1.26687325\n",
      " -0.02231576 -0.30105381  1.17578863  0.34494587  0.5290753   1.17587187\n",
      "  0.15688631  0.11225932 -1.73958652 -0.72079782  0.3442684  -0.30368063\n",
      " -0.72061645 -0.30380494 -0.30484824 -1.73624419 -1.73669906 -0.39598946\n",
      " -1.69128389  0.80921078 -0.85627669 -1.50674477 -0.94916601 -0.48739466\n",
      "  1.17572162  0.11155275  1.17472298 -0.3023287   0.80447774 -0.85690073\n",
      "  0.25198743  1.12871214 -0.76335552  0.80660746  0.80694163 -1.08782583\n",
      " -1.69062263  1.26613848  0.80725478  0.80650738 -0.487017   -0.02568693\n",
      " -0.25553432  0.80647865  0.80660406 -1.73450387  0.80643525  0.34277246\n",
      "  1.17592572  0.80803611 -0.02547585  0.34467467  1.17627523  0.80697292\n",
      "  0.80260416 -0.02577391 -0.21085456  0.52928249  0.80795135  0.80861219\n",
      " -2.52171615  0.80746361 -0.94972863  0.80846138 -0.21124    -1.73635892\n",
      " -1.73857745  0.80524876 -1.18055343  0.02102368 -0.39418898  0.06776194\n",
      "  0.80582864 -2.70859822  0.80715036  1.12869905 -0.72275414 -0.25440045\n",
      "  0.80728988  0.1130717  -0.85660265  0.80714799  0.30195034  0.80730458\n",
      "  0.34464864  0.34293349 -0.30444247  0.809288    1.17541734 -1.73926539\n",
      " -1.87449101  0.30211559 -0.07210618 -0.8560173  -2.52091139 -1.50410899\n",
      "  0.06714425 -0.85786568  0.80825397  0.02151516  0.20453983 -1.73928868\n",
      "  0.57723704  0.80694098 -1.46033175  0.80712617  0.34317061  0.80913457\n",
      " -0.30243378  1.1295316   1.17533115  0.06736386  0.20437299 -1.73844252\n",
      "  1.1760765  -1.64109604  0.11228362 -1.13329084 -0.07559032  1.12880294\n",
      " -1.73787428]\n",
      "[ 0.80577 -1.134    1.1752  -0.76397  1.12814  1.26687 -0.02232 -0.30105\n",
      "  1.17579  0.34495  0.52908  1.17587  0.15689  0.11226 -1.73959 -0.7208\n",
      "  0.34427 -0.30368 -0.72062 -0.3038  -0.30485 -1.73624 -1.7367  -0.39599\n",
      " -1.69128  0.80921 -0.85628 -1.50674 -0.94917 -0.48739  1.17572  0.11155\n",
      "  1.17472 -0.30233  0.80448 -0.8569   0.25199  1.12871 -0.76336  0.80661\n",
      "  0.80694 -1.08783 -1.69062  1.26614  0.80725  0.80651 -0.48702 -0.02569\n",
      " -0.25553  0.80648  0.8066  -1.7345   0.80644  0.34277  1.17593  0.80804\n",
      " -0.02548  0.34467  1.17628  0.80697  0.8026  -0.02577 -0.21085  0.52928\n",
      "  0.80795  0.80861 -2.52172  0.80746 -0.94973  0.80846 -0.21124 -1.73636\n",
      " -1.73858  0.80525 -1.18055  0.02102 -0.39419  0.06776  0.80583 -2.7086\n",
      "  0.80715  1.1287  -0.72275 -0.2544   0.80729  0.11307 -0.8566   0.80715\n",
      "  0.30195  0.8073   0.34465  0.34293 -0.30444  0.80929  1.17542 -1.73927\n",
      " -1.87449  0.30212 -0.07211 -0.85602 -2.52091 -1.50411  0.06714 -0.85787\n",
      "  0.80825  0.02152  0.20454 -1.73929  0.57724  0.80694 -1.46033  0.80713\n",
      "  0.34317  0.80913 -0.30243  1.12953  1.17533  0.06736  0.20437 -1.73844\n",
      "  1.17608 -1.6411   0.11228 -1.13329 -0.07559  1.1288  -1.73787]\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
